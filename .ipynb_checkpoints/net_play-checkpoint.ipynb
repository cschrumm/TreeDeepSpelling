{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imgCls.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv2 = nn.Conv2d(1,32,2,1)\n",
    "cnv3 = nn.Conv2d(32,16,2,1,padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ry = torch.rand(1,1,3,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  torch.Size([1, 16, 3, 256])  Data type:  torch.float32  Device:  cpu  Requires grad:  True\n"
     ]
    }
   ],
   "source": [
    "tt = cnv3(cnv2(ry))\n",
    "pt_info(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttp = F.max_pool2d(tt, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  torch.Size([1, 16, 1, 128])  Data type:  torch.float32  Device:  cpu  Requires grad:  True\n"
     ]
    }
   ],
   "source": [
    "pt_info(ttp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "zr = torch.zeros((1,1,3,256))\n",
    "zr = zr.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  torch.Size([1, 2048])  Data type:  torch.float32  Device:  cpu  Requires grad:  True\n"
     ]
    }
   ],
   "source": [
    "pt_info(torch.flatten(ttp,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImgNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm = ImgNet(4)\n",
    "imm.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  torch.Size([2, 16, 1, 128])  Data type:  torch.float32  Device:  cuda:0  Requires grad:  True\n",
      "Size:  torch.Size([2, 2048])  Data type:  torch.float32  Device:  cuda:0  Requires grad:  True\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 2, 255]             160\n",
      "            Conv2d-2           [-1, 16, 3, 256]           2,064\n",
      "         Dropout2d-3           [-1, 16, 1, 128]               0\n",
      "            Linear-4                   [-1, 64]         131,136\n",
      "         Dropout2d-5                   [-1, 64]               0\n",
      "            Linear-6                    [-1, 4]             260\n",
      "================================================================\n",
      "Total params: 133,620\n",
      "Trainable params: 133,620\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.23\n",
      "Params size (MB): 0.51\n",
      "Estimated Total Size (MB): 0.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(imm,(1,3,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  torch.Size([1, 16, 1, 128])  Data type:  torch.float32  Device:  cuda:0  Requires grad:  True\n",
      "Size:  torch.Size([1, 2048])  Data type:  torch.float32  Device:  cuda:0  Requires grad:  True\n"
     ]
    }
   ],
   "source": [
    "vlu = imm(zr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit imm(zr)\n",
    "\n",
    "for i in range(100000):\n",
    "    v = imm(zr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2232, 0.2749, 0.2656, 0.2363]], device='cuda:0',\n",
       "       grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(vlu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, device='cuda:0')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.exp(vlu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot = cnv2(ry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  torch.Size([1, 32, 2, 255])  Data type:  torch.float32  Device:  cpu  Requires grad:  True\n"
     ]
    }
   ],
   "source": [
    "pt_info(ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_info(ot):\n",
    "    print(\"Size: \",ot.size(),\" Data type: \", ot.dtype,\" Device: \",ot.device, \" Requires grad: \", ot.requires_grad)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot2 = cnv3(ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  torch.Size([1, 64, 2, 255])  Data type:  torch.float32  Device:  cpu  Requires grad:  True\n"
     ]
    }
   ],
   "source": [
    "pt_info(ot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  torch.Size([1, 32640])  Data type:  torch.float32  Device:  cpu  Requires grad:  True\n"
     ]
    }
   ],
   "source": [
    "pt_info(torch.flatten(ot2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnv3.out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  torch.Size([1, 64, 126, 1])  Data type:  torch.float32  Device:  cpu  Requires grad:  True\n"
     ]
    }
   ],
   "source": [
    "pt_info(ot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m'pickle'\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m'/home/chris-s/anaconda3/lib/python3.7/pickle.py'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Saves an object to a disk file.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also: :ref:`recommend-saving-models`\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        obj: saved object\u001b[0m\n",
       "\u001b[0;34m        f: a file-like object (has to implement write and flush) or a string\u001b[0m\n",
       "\u001b[0;34m           containing a file name\u001b[0m\n",
       "\u001b[0;34m        pickle_module: module used for pickling metadata and objects\u001b[0m\n",
       "\u001b[0;34m        pickle_protocol: can be specified to override the default protocol\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. warning::\u001b[0m\n",
       "\u001b[0;34m        If you are using Python 2, :func:`torch.save` does NOT support :class:`StringIO.StringIO`\u001b[0m\n",
       "\u001b[0;34m        as a valid file-like object. This is because the write method should return\u001b[0m\n",
       "\u001b[0;34m        the number of bytes written; :meth:`StringIO.write()` does not do this.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Please use something like :class:`io.BytesIO` instead.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Example:\u001b[0m\n",
       "\u001b[0;34m        >>> # Save to file\u001b[0m\n",
       "\u001b[0;34m        >>> x = torch.tensor([0, 1, 2, 3, 4])\u001b[0m\n",
       "\u001b[0;34m        >>> torch.save(x, 'tensor.pt')\u001b[0m\n",
       "\u001b[0;34m        >>> # Save to io.BytesIO buffer\u001b[0m\n",
       "\u001b[0;34m        >>> buffer = io.BytesIO()\u001b[0m\n",
       "\u001b[0;34m        >>> torch.save(x, buffer)\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight', tensor([[[[-0.3213,  0.1610],\n",
       "                        [-0.3686,  0.0440]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4509, -0.4955],\n",
       "                        [-0.3059,  0.1684]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3357,  0.0006],\n",
       "                        [ 0.0101,  0.2383]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0071,  0.3796],\n",
       "                        [ 0.4230,  0.2304]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4671, -0.2018],\n",
       "                        [-0.1958, -0.0943]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0595, -0.0694],\n",
       "                        [-0.0538,  0.3777]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3528,  0.1268],\n",
       "                        [ 0.3884,  0.2135]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3546,  0.1866],\n",
       "                        [ 0.2908,  0.0210]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1900,  0.4039],\n",
       "                        [ 0.2023,  0.0338]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2685, -0.4769],\n",
       "                        [-0.4221,  0.1122]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0536, -0.1632],\n",
       "                        [-0.0609, -0.4446]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4259, -0.2667],\n",
       "                        [ 0.1074, -0.4721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4684,  0.2195],\n",
       "                        [ 0.4177, -0.2393]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4134,  0.4300],\n",
       "                        [ 0.3926, -0.2384]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.4898,  0.0109],\n",
       "                        [-0.0655,  0.3630]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3313,  0.0342],\n",
       "                        [-0.1297, -0.4287]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0697, -0.2952],\n",
       "                        [-0.0077,  0.0844]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1729,  0.0696],\n",
       "                        [ 0.2382, -0.3964]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4642,  0.3292],\n",
       "                        [ 0.2211,  0.1198]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2016, -0.0177],\n",
       "                        [ 0.3798,  0.1072]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2369,  0.4544],\n",
       "                        [-0.0985, -0.0599]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3055, -0.0179],\n",
       "                        [ 0.4780,  0.3414]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2105, -0.4477],\n",
       "                        [ 0.0329, -0.0718]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1669, -0.0726],\n",
       "                        [-0.0987, -0.4528]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1322, -0.2540],\n",
       "                        [ 0.0739, -0.1233]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1970,  0.2752],\n",
       "                        [ 0.4830,  0.4770]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1778,  0.0158],\n",
       "                        [ 0.3280,  0.2528]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1026, -0.1700],\n",
       "                        [-0.2236,  0.3009]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0168,  0.3306],\n",
       "                        [-0.4409, -0.0744]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.3971, -0.2961],\n",
       "                        [-0.1447, -0.2073]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.4348,  0.1778],\n",
       "                        [ 0.3598, -0.1502]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3914,  0.4228],\n",
       "                        [ 0.2494,  0.3028]]]], device='cuda:0')),\n",
       "             ('conv1.bias',\n",
       "              tensor([ 0.0266, -0.2661, -0.1242,  0.2734, -0.2291,  0.4859,  0.2072, -0.4834,\n",
       "                       0.4965, -0.0845, -0.0647, -0.0348,  0.0288,  0.3661,  0.2918, -0.1392,\n",
       "                       0.3912,  0.1012, -0.1003, -0.1680, -0.4022,  0.0892,  0.1432, -0.2932,\n",
       "                      -0.1376,  0.0170,  0.0395, -0.4048, -0.1401,  0.4812, -0.2532, -0.0402],\n",
       "                     device='cuda:0')),\n",
       "             ('conv2.weight', tensor([[[[-0.0269, -0.0009],\n",
       "                        [-0.0025, -0.0314]],\n",
       "              \n",
       "                       [[ 0.0185, -0.0209],\n",
       "                        [ 0.0308, -0.0494]],\n",
       "              \n",
       "                       [[ 0.0107,  0.0260],\n",
       "                        [-0.0298,  0.0363]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0186,  0.0330],\n",
       "                        [ 0.0072, -0.0345]],\n",
       "              \n",
       "                       [[ 0.0474,  0.0601],\n",
       "                        [-0.0228,  0.0182]],\n",
       "              \n",
       "                       [[-0.0298,  0.0768],\n",
       "                        [ 0.0480,  0.0727]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0805,  0.0681],\n",
       "                        [-0.0099,  0.0312]],\n",
       "              \n",
       "                       [[ 0.0473,  0.0701],\n",
       "                        [-0.0428, -0.0620]],\n",
       "              \n",
       "                       [[ 0.0404,  0.0553],\n",
       "                        [-0.0643, -0.0225]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0487,  0.0739],\n",
       "                        [-0.0787,  0.0442]],\n",
       "              \n",
       "                       [[ 0.0757,  0.0062],\n",
       "                        [ 0.0745,  0.0183]],\n",
       "              \n",
       "                       [[-0.0101,  0.0258],\n",
       "                        [ 0.0374, -0.0453]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0390, -0.0853],\n",
       "                        [-0.0258,  0.0361]],\n",
       "              \n",
       "                       [[ 0.0062, -0.0624],\n",
       "                        [ 0.0558, -0.0433]],\n",
       "              \n",
       "                       [[ 0.0264, -0.0085],\n",
       "                        [-0.0503,  0.0379]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0407, -0.0571],\n",
       "                        [-0.0739, -0.0449]],\n",
       "              \n",
       "                       [[ 0.0037,  0.0529],\n",
       "                        [-0.0599,  0.0012]],\n",
       "              \n",
       "                       [[-0.0590,  0.0235],\n",
       "                        [ 0.0270,  0.0137]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0608,  0.0110],\n",
       "                        [-0.0018, -0.0040]],\n",
       "              \n",
       "                       [[-0.0026,  0.0484],\n",
       "                        [ 0.0487, -0.0065]],\n",
       "              \n",
       "                       [[-0.0528,  0.0859],\n",
       "                        [-0.0657,  0.0206]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0452,  0.0543],\n",
       "                        [ 0.0765, -0.0116]],\n",
       "              \n",
       "                       [[-0.0758,  0.0170],\n",
       "                        [-0.0183,  0.0406]],\n",
       "              \n",
       "                       [[-0.0791,  0.0611],\n",
       "                        [ 0.0266,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0745,  0.0438],\n",
       "                        [ 0.0797, -0.0503]],\n",
       "              \n",
       "                       [[ 0.0854, -0.0144],\n",
       "                        [ 0.0631,  0.0335]],\n",
       "              \n",
       "                       [[ 0.0390,  0.0105],\n",
       "                        [-0.0352,  0.0568]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0102, -0.0829],\n",
       "                        [-0.0341, -0.0361]],\n",
       "              \n",
       "                       [[-0.0065, -0.0098],\n",
       "                        [ 0.0333,  0.0751]],\n",
       "              \n",
       "                       [[-0.0496, -0.0697],\n",
       "                        [ 0.0572, -0.0833]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0222, -0.0481],\n",
       "                        [-0.0630,  0.0482]],\n",
       "              \n",
       "                       [[-0.0290,  0.0785],\n",
       "                        [ 0.0456,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0837,  0.0249],\n",
       "                        [ 0.0811, -0.0800]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0718,  0.0329],\n",
       "                        [ 0.0067,  0.0199]],\n",
       "              \n",
       "                       [[-0.0854, -0.0212],\n",
       "                        [-0.0129,  0.0318]],\n",
       "              \n",
       "                       [[ 0.0202,  0.0273],\n",
       "                        [ 0.0811,  0.0618]]]], device='cuda:0')),\n",
       "             ('conv2.bias',\n",
       "              tensor([-0.0403,  0.0451,  0.0506, -0.0254, -0.0321, -0.0308,  0.0693,  0.0540,\n",
       "                      -0.0430, -0.0237, -0.0131, -0.0855,  0.0797, -0.0450,  0.0668, -0.0811],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0063,  0.0123, -0.0048,  ...,  0.0076,  0.0034, -0.0093],\n",
       "                      [-0.0051,  0.0076,  0.0063,  ...,  0.0144, -0.0152,  0.0147],\n",
       "                      [ 0.0147,  0.0025,  0.0063,  ...,  0.0175, -0.0012, -0.0176],\n",
       "                      ...,\n",
       "                      [-0.0097,  0.0068,  0.0125,  ..., -0.0112, -0.0075, -0.0208],\n",
       "                      [-0.0101, -0.0199,  0.0212,  ...,  0.0099,  0.0190, -0.0041],\n",
       "                      [-0.0024,  0.0032,  0.0036,  ...,  0.0145,  0.0039, -0.0030]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0046,  0.0048, -0.0160,  0.0035, -0.0152,  0.0096,  0.0122,  0.0042,\n",
       "                      -0.0060, -0.0027,  0.0089,  0.0060, -0.0130, -0.0101,  0.0043, -0.0145,\n",
       "                      -0.0074,  0.0176, -0.0196, -0.0032,  0.0147,  0.0148,  0.0005,  0.0101,\n",
       "                       0.0099,  0.0166, -0.0213,  0.0178, -0.0104, -0.0072, -0.0072,  0.0032,\n",
       "                       0.0161,  0.0029, -0.0027, -0.0081, -0.0174, -0.0063,  0.0038,  0.0113,\n",
       "                       0.0111, -0.0014, -0.0079, -0.0203, -0.0128, -0.0152, -0.0188, -0.0188,\n",
       "                      -0.0091, -0.0141, -0.0070, -0.0166,  0.0118, -0.0092,  0.0120, -0.0099,\n",
       "                      -0.0117,  0.0195,  0.0005, -0.0123,  0.0099, -0.0135, -0.0081, -0.0096],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-1.8445e-02,  1.1117e-01, -9.2796e-02, -7.0184e-06, -1.0184e-01,\n",
       "                        5.2730e-02,  9.2322e-02, -4.7196e-02,  1.0750e-02, -1.1238e-01,\n",
       "                        8.9533e-02, -1.1430e-01,  6.0264e-02,  9.3961e-02, -1.1708e-01,\n",
       "                       -1.0139e-01, -7.4529e-02, -8.7952e-02,  9.0652e-02,  1.1540e-01,\n",
       "                       -5.9997e-02,  5.5292e-02,  9.5555e-02, -2.6075e-02, -7.9248e-02,\n",
       "                        1.0382e-01, -7.1318e-02,  6.2484e-02, -1.0808e-01,  5.5620e-02,\n",
       "                        3.6471e-02,  1.6899e-02, -3.2764e-02,  1.1995e-01,  6.4221e-02,\n",
       "                        7.3432e-02,  5.5056e-02,  7.1487e-02, -1.1161e-02,  7.9725e-02,\n",
       "                       -8.8832e-02, -1.2040e-01,  2.7791e-03, -1.2071e-01, -1.8973e-03,\n",
       "                        1.0251e-01, -5.9406e-02, -1.7607e-02, -2.9314e-03, -8.8171e-03,\n",
       "                       -8.4507e-02,  3.8106e-03, -1.1046e-02,  6.7541e-03,  5.7929e-02,\n",
       "                       -7.1770e-02, -1.2023e-01, -1.2046e-01, -5.0919e-02,  1.9286e-02,\n",
       "                       -6.7389e-02, -3.5415e-03, -1.1487e-02,  4.8363e-02],\n",
       "                      [ 1.9248e-03, -8.7351e-02,  6.4463e-02, -7.6369e-02, -4.7100e-02,\n",
       "                       -3.8832e-02,  1.0477e-02, -4.1683e-02, -5.2411e-03,  1.2314e-01,\n",
       "                       -2.9252e-02,  4.8659e-02,  1.2570e-02, -1.0940e-01, -7.4483e-02,\n",
       "                        7.8986e-02,  5.5260e-02,  1.3517e-02,  9.2015e-02,  3.1185e-02,\n",
       "                       -7.3460e-02, -5.2156e-02, -6.9710e-02, -3.1143e-05,  1.1732e-01,\n",
       "                        3.2061e-02,  1.1398e-01,  3.6484e-02, -8.9429e-02, -1.0308e-01,\n",
       "                        2.6773e-02,  9.6079e-02, -1.0917e-01, -9.3158e-02,  1.0403e-01,\n",
       "                        5.6588e-02,  9.3448e-02, -8.7031e-02, -5.7946e-02,  1.1832e-01,\n",
       "                        9.8923e-02,  2.3346e-02,  1.0700e-01,  6.1530e-02, -1.0911e-01,\n",
       "                        7.6118e-02, -3.7528e-02, -1.2365e-01, -8.9183e-02,  6.4173e-02,\n",
       "                       -2.6764e-02,  8.3250e-02,  8.5320e-02,  1.0917e-01, -8.6472e-02,\n",
       "                       -5.6873e-02, -9.8924e-02,  4.2350e-02,  4.7679e-02,  6.8017e-03,\n",
       "                        1.1669e-01,  5.2739e-02, -2.3717e-02,  7.9236e-02],\n",
       "                      [-5.3759e-03, -4.9923e-03, -6.1971e-02,  9.1702e-02,  8.0357e-02,\n",
       "                       -8.2759e-02, -1.1805e-01,  5.1232e-02, -6.2655e-02, -9.2694e-02,\n",
       "                        1.1843e-01,  4.3898e-02,  6.0383e-02, -5.6914e-02,  1.6095e-02,\n",
       "                        3.9065e-02,  1.0341e-01,  1.7754e-02,  5.5059e-02, -7.6844e-02,\n",
       "                        2.2174e-02, -5.7254e-02,  5.7295e-02,  1.2353e-01,  4.2050e-03,\n",
       "                        1.0355e-01, -7.8633e-02,  6.7760e-03,  7.1287e-02, -6.4247e-02,\n",
       "                       -3.5994e-03, -1.0566e-01,  1.0708e-01,  1.2636e-02,  8.8536e-02,\n",
       "                        4.4235e-02, -8.8092e-02,  1.0166e-01, -2.6934e-02, -7.2984e-02,\n",
       "                        1.0467e-01, -3.5465e-02, -6.1492e-03,  4.8867e-02,  5.4786e-02,\n",
       "                        4.3933e-02,  2.7085e-02,  2.9318e-02,  1.2038e-01, -1.0338e-01,\n",
       "                        9.1837e-02,  9.5124e-02, -3.0287e-02, -3.1148e-02, -1.1292e-01,\n",
       "                       -8.0347e-02,  8.6864e-02, -3.6869e-02,  1.2458e-01,  8.9397e-04,\n",
       "                        9.7849e-02, -1.1488e-01, -5.0572e-02, -3.2843e-02],\n",
       "                      [ 6.1325e-02, -2.1828e-02,  4.4516e-02,  2.3050e-02, -1.2308e-01,\n",
       "                       -8.5101e-02,  6.3196e-03, -1.3555e-02, -1.9129e-03,  2.0420e-02,\n",
       "                       -3.7678e-03, -9.0346e-02, -2.0942e-02,  1.1658e-01, -1.8915e-03,\n",
       "                       -2.4853e-02, -9.8223e-02,  5.7036e-02, -3.7055e-02,  1.9300e-04,\n",
       "                        5.7812e-02, -3.0465e-02,  3.8732e-02,  1.0532e-01, -1.2375e-01,\n",
       "                        1.1379e-01, -9.9606e-02,  3.3493e-02, -7.5357e-02, -5.6350e-03,\n",
       "                       -5.4894e-02, -3.9911e-02, -8.7138e-02, -8.9556e-02, -7.9865e-02,\n",
       "                        5.1325e-02,  7.8109e-02,  1.1583e-01,  3.3096e-02, -2.2459e-02,\n",
       "                       -5.4757e-02, -7.3507e-02, -9.7020e-04,  1.0978e-01, -9.3284e-02,\n",
       "                       -6.4816e-02,  8.5587e-02,  7.5175e-02, -3.0422e-02,  6.9695e-02,\n",
       "                        7.7873e-02,  8.6138e-02, -6.6620e-02,  1.1220e-01,  2.0984e-03,\n",
       "                       -2.2916e-02, -7.9212e-02,  9.5599e-02, -2.1457e-02, -5.9358e-02,\n",
       "                       -1.2497e-01, -4.8205e-02,  5.9596e-02,  6.2824e-02]], device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.1005,  0.0147,  0.0586, -0.0460], device='cuda:0'))])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
